{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T20:52:41.434792Z",
     "start_time": "2021-12-03T20:52:39.128699Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-01T03:12:23.844084Z",
     "iopub.status.busy": "2021-12-01T03:12:23.843863Z",
     "iopub.status.idle": "2021-12-01T03:12:25.600437Z",
     "shell.execute_reply": "2021-12-01T03:12:25.599524Z",
     "shell.execute_reply.started": "2021-12-01T03:12:23.844057Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import re\n",
    "from nltk import FreqDist\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import ast # used for converting column values to lists post-import from csv\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, plot_confusion_matrix, plot_roc_curve, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # supresses errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T20:52:41.449816Z",
     "start_time": "2021-12-03T20:52:41.436804Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-01T03:17:56.430873Z",
     "iopub.status.busy": "2021-12-01T03:17:56.430399Z",
     "iopub.status.idle": "2021-12-01T03:17:56.450233Z",
     "shell.execute_reply": "2021-12-01T03:17:56.449219Z",
     "shell.execute_reply.started": "2021-12-01T03:17:56.430829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a list of the nltk's English-language stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T20:52:41.465817Z",
     "start_time": "2021-12-03T20:52:41.451801Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-01T03:17:56.451822Z",
     "iopub.status.busy": "2021-12-01T03:17:56.451421Z",
     "iopub.status.idle": "2021-12-01T03:17:56.455964Z",
     "shell.execute_reply": "2021-12-01T03:17:56.455367Z",
     "shell.execute_reply.started": "2021-12-01T03:17:56.451783Z"
    }
   },
   "outputs": [],
   "source": [
    "# a small function to quickly remove stopwords from the 'step_tokens' column \n",
    "def remove_stop_words(count, stop_words):\n",
    "    for x in count.index:\n",
    "        if x in stop_words:\n",
    "            count = count.drop(x)\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T20:52:41.480806Z",
     "start_time": "2021-12-03T20:52:41.468814Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-01T03:18:55.560460Z",
     "iopub.status.busy": "2021-12-01T03:18:55.559926Z",
     "iopub.status.idle": "2021-12-01T03:18:55.581256Z",
     "shell.execute_reply": "2021-12-01T03:18:55.580303Z",
     "shell.execute_reply.started": "2021-12-01T03:18:55.560415Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(estimator, X_tr, X_te, y_tr, y_te, cv=5):\n",
    "    '''\n",
    "Function takes in estimator, training data, test data, \n",
    "and the cross validation splitting strategy, and returns the accuracy, precision, recall, f1 and the ROC-AUC\n",
    "scores for the model as well as a confusion matrix visualization.  From Phase 3 Project: \n",
    "https://github.com/Nindorph/TanzanianWaterWells/blob/main/Modeling_Final.ipynb and Lindsey Berlin’s evaluate function\n",
    "found at: \n",
    "https://github.com/lindseyberlin/Cat-in-the-Dat-Project/blob/main/notebooks/Lindsey/EDA-Initial-Models.ipynb\n",
    "------------------------------------------------------------------------------------------\n",
    "Inputs: \n",
    "-Estimator - Estimator object  \n",
    "-X_tr – X_train dataframe\n",
    "-X_te – X_test dataframe\n",
    "-Y_tr – y_train dataframe\n",
    "-Y_te – y_test dataframe\n",
    "-Cv – If cross_val  set to true this determines the cross-validation splitting strategy.  \n",
    "        Takes in all value options for sklearn.model_selection_cross_val_score “cv” parameter:\n",
    "        - None, to use the default 5-fold cross validation,\n",
    "        - int, to specify the number of folds in a (Stratified)KFold,\n",
    "        - CV splitter,\n",
    "        - An iterable yielding (train, test) splits as arrays of indices\n",
    "\n",
    "\n",
    "Returns – nothing is returned \n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    output = cross_validate(estimator, X_tr, y_tr, cv=cv,\n",
    "                            scoring=['accuracy', 'precision','recall', 'f1', 'roc_auc'])\n",
    "    #Printing out the mean of all of our evaluating metrics across the cross validation. \n",
    "    #Accuracy, precisionc recall, f1, and roc auc\n",
    "    print('Results of Cross-Validation:\\n')\n",
    "    print(f'Average accuracy: {output[\"test_accuracy\"].mean()}\\\n",
    "    +/- {output[\"test_accuracy\"].std()}')\n",
    "    print(f'Average precision: {output[\"test_precision\"].mean()}\\\n",
    "    +/- {output[\"test_precision\"].std()}')\n",
    "    print(f'**Average recall: {output[\"test_recall\"].mean()}\\\n",
    "    +/- {output[\"test_recall\"].std()}')\n",
    "    print(f'Average f1 score: {output[\"test_f1\"].mean()}\\\n",
    "    +/- {output[\"test_f1\"].std()}')\n",
    "    print(f'Average roc_auc: {output[\"test_roc_auc\"].mean()}\\\n",
    "    +/- {output[\"test_roc_auc\"].std()}\\n')\n",
    "    print('+'*20)\n",
    "\n",
    "\n",
    "    #Fitting the estimator to our X and y train data\n",
    "    estimator.fit(X_tr, y_tr)\n",
    "    #getting predictions for X train\n",
    "    tr_preds = estimator.predict(X_tr)\n",
    "    #getting predictions for X test\n",
    "    te_preds = estimator.predict(X_te)\n",
    "\n",
    "    #Creating a confusion matrix from our data with custom labels\n",
    "    print('\\nResults of Train-Test Split Validation:')\n",
    "    plot_confusion_matrix(estimator, X_te, y_te, cmap='mako')\n",
    "    plt.show()\n",
    "\n",
    "    #Printing our final evaluating metrics across X train\n",
    "    #Evaluating using accuracy, precision, recall, f1, roc auc\n",
    "    print(\"\\nTraining Scores:\")\n",
    "    print(f\"Train accuracy: {accuracy_score(y_tr, tr_preds)}\")\n",
    "    print(f\"Train precision: {precision_score(y_tr, tr_preds)}\")\n",
    "    print(f\"**Train recall: {recall_score(y_tr, tr_preds)}\")\n",
    "    print(f\"Train f1 score: {f1_score(y_tr, tr_preds)}\")\n",
    "    print(f\"Train roc_auc: {roc_auc_score(y_tr, tr_preds)}\\n\")\n",
    "    print(\"<>\"*10)\n",
    "    #Printing our final evaluating metrics across X test\n",
    "    #Evaluating using accuracy, precision, recall, f1, roc auc\n",
    "    print(\"\\nTesting Scores:\")\n",
    "    print(f\"Test accuracy: {accuracy_score(y_te, te_preds)}\")\n",
    "    print(f\"Test precision: {precision_score(y_te, te_preds)}\")\n",
    "    print(f\"**Test recall: {recall_score(y_te, te_preds)}\")\n",
    "    print(f\"Test f1 score: {f1_score(y_te, te_preds)}\")\n",
    "    print(f\"Test roc_auc: {roc_auc_score(y_te, te_preds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T20:52:42.950101Z",
     "start_time": "2021-12-03T20:52:41.481807Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/X_train.csv', index_col=0)\n",
    "X_test = pd.read_csv('../data/X_test.csv', index_col=0)\n",
    "y_train = pd.read_csv('../data/y_train.csv', index_col=0)\n",
    "y_test = pd.read_csv('../data/y_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T20:54:00.863395Z",
     "start_time": "2021-12-03T20:54:00.701740Z"
    }
   },
   "outputs": [],
   "source": [
    "X_holdout = pd.read_csv('../data/X_holdout.csv', index_col=0)\n",
    "y_holdout = pd.read_csv('../data/y_holdout.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T20:54:02.375681Z",
     "start_time": "2021-12-03T20:54:02.361665Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train target\n",
      "0         68716\n",
      "1         68577\n",
      "dtype: int64\n",
      "Test  target\n",
      "1         20714\n",
      "0         20474\n",
      "dtype: int64\n",
      "Holdout target\n",
      "0         8877\n",
      "1         8776\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Train {y_train.value_counts()}')\n",
    "print(f'Test  {y_test.value_counts()}')\n",
    "print(f'Holdout {y_holdout.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T20:55:09.264665Z",
     "start_time": "2021-12-03T20:55:09.250662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_description</th>\n",
       "      <th>cleaned_steps</th>\n",
       "      <th>cleaned_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47827</th>\n",
       "      <td>i tried some recipes for making sweet sour sau...</td>\n",
       "      <td>add the oil sugar and vinegar to a small sauce...</td>\n",
       "      <td>sugar vinegar ketchup water pineapple juice co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129467</th>\n",
       "      <td>this is the soup that moroccans traditionally ...</td>\n",
       "      <td>place the lamb turmeric black pepper cinnamon ...</td>\n",
       "      <td>lamb ground turmeric ground black pepper groun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184947</th>\n",
       "      <td>i really loved my friends lemon chicken pasta ...</td>\n",
       "      <td>cook chicken your favorite way i usually salt ...</td>\n",
       "      <td>chicken pasta avocados olive oil green onion f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98991</th>\n",
       "      <td>a nice change to the tradtional gratin \\r \\r w...</td>\n",
       "      <td>preheat the oven to cfan cgas put the cream ga...</td>\n",
       "      <td>double cream garlic cloves fresh thyme leave p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159123</th>\n",
       "      <td>this has amazed our guests for years but is so...</td>\n",
       "      <td>in a large nonreactive pot with lid melt butte...</td>\n",
       "      <td>unsalted butter garlic cloves fresh ground bla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_description  \\\n",
       "47827   i tried some recipes for making sweet sour sau...   \n",
       "129467  this is the soup that moroccans traditionally ...   \n",
       "184947  i really loved my friends lemon chicken pasta ...   \n",
       "98991   a nice change to the tradtional gratin \\r \\r w...   \n",
       "159123  this has amazed our guests for years but is so...   \n",
       "\n",
       "                                            cleaned_steps  \\\n",
       "47827   add the oil sugar and vinegar to a small sauce...   \n",
       "129467  place the lamb turmeric black pepper cinnamon ...   \n",
       "184947  cook chicken your favorite way i usually salt ...   \n",
       "98991   preheat the oven to cfan cgas put the cream ga...   \n",
       "159123  in a large nonreactive pot with lid melt butte...   \n",
       "\n",
       "                                      cleaned_ingredients  \n",
       "47827   sugar vinegar ketchup water pineapple juice co...  \n",
       "129467  lamb ground turmeric ground black pepper groun...  \n",
       "184947  chicken pasta avocados olive oil green onion f...  \n",
       "98991   double cream garlic cloves fresh thyme leave p...  \n",
       "159123  unsalted butter garlic cloves fresh ground bla...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the data for vectorization the columns containing text will have to be combined into a single string that will be used in the model to meet the input requirements for the vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T20:55:15.661479Z",
     "start_time": "2021-12-03T20:55:15.330400Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-01T03:20:15.549984Z",
     "iopub.status.busy": "2021-12-01T03:20:15.549741Z",
     "iopub.status.idle": "2021-12-01T03:20:16.218890Z",
     "shell.execute_reply": "2021-12-01T03:20:16.218258Z",
     "shell.execute_reply.started": "2021-12-01T03:20:15.549955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_description</th>\n",
       "      <th>cleaned_steps</th>\n",
       "      <th>cleaned_ingredients</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47827</th>\n",
       "      <td>i tried some recipes for making sweet sour sau...</td>\n",
       "      <td>add the oil sugar and vinegar to a small sauce...</td>\n",
       "      <td>sugar vinegar ketchup water pineapple juice co...</td>\n",
       "      <td>i tried some recipes for making sweet sour sau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129467</th>\n",
       "      <td>this is the soup that moroccans traditionally ...</td>\n",
       "      <td>place the lamb turmeric black pepper cinnamon ...</td>\n",
       "      <td>lamb ground turmeric ground black pepper groun...</td>\n",
       "      <td>this is the soup that moroccans traditionally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184947</th>\n",
       "      <td>i really loved my friends lemon chicken pasta ...</td>\n",
       "      <td>cook chicken your favorite way i usually salt ...</td>\n",
       "      <td>chicken pasta avocados olive oil green onion f...</td>\n",
       "      <td>i really loved my friends lemon chicken pasta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98991</th>\n",
       "      <td>a nice change to the tradtional gratin \\r \\r w...</td>\n",
       "      <td>preheat the oven to cfan cgas put the cream ga...</td>\n",
       "      <td>double cream garlic cloves fresh thyme leave p...</td>\n",
       "      <td>a nice change to the tradtional gratin \\r \\r w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159123</th>\n",
       "      <td>this has amazed our guests for years but is so...</td>\n",
       "      <td>in a large nonreactive pot with lid melt butte...</td>\n",
       "      <td>unsalted butter garlic cloves fresh ground bla...</td>\n",
       "      <td>this has amazed our guests for years but is so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_description  \\\n",
       "47827   i tried some recipes for making sweet sour sau...   \n",
       "129467  this is the soup that moroccans traditionally ...   \n",
       "184947  i really loved my friends lemon chicken pasta ...   \n",
       "98991   a nice change to the tradtional gratin \\r \\r w...   \n",
       "159123  this has amazed our guests for years but is so...   \n",
       "\n",
       "                                            cleaned_steps  \\\n",
       "47827   add the oil sugar and vinegar to a small sauce...   \n",
       "129467  place the lamb turmeric black pepper cinnamon ...   \n",
       "184947  cook chicken your favorite way i usually salt ...   \n",
       "98991   preheat the oven to cfan cgas put the cream ga...   \n",
       "159123  in a large nonreactive pot with lid melt butte...   \n",
       "\n",
       "                                      cleaned_ingredients  \\\n",
       "47827   sugar vinegar ketchup water pineapple juice co...   \n",
       "129467  lamb ground turmeric ground black pepper groun...   \n",
       "184947  chicken pasta avocados olive oil green onion f...   \n",
       "98991   double cream garlic cloves fresh thyme leave p...   \n",
       "159123  unsalted butter garlic cloves fresh ground bla...   \n",
       "\n",
       "                                                 combined  \n",
       "47827   i tried some recipes for making sweet sour sau...  \n",
       "129467  this is the soup that moroccans traditionally ...  \n",
       "184947  i really loved my friends lemon chicken pasta ...  \n",
       "98991   a nice change to the tradtional gratin \\r \\r w...  \n",
       "159123  this has amazed our guests for years but is so...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new column compatible with vectorizer inputs \n",
    "X_train['combined'] = X_train['cleaned_description'].str.cat(X_train[['cleaned_steps',\n",
    "                                                                      'cleaned_ingredients']],sep=\" \")\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T20:55:19.629724Z",
     "start_time": "2021-12-03T20:55:19.529696Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-01T03:20:16.220535Z",
     "iopub.status.busy": "2021-12-01T03:20:16.220135Z",
     "iopub.status.idle": "2021-12-01T03:20:16.437249Z",
     "shell.execute_reply": "2021-12-01T03:20:16.436436Z",
     "shell.execute_reply.started": "2021-12-01T03:20:16.220487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_description</th>\n",
       "      <th>cleaned_steps</th>\n",
       "      <th>cleaned_ingredients</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97436</th>\n",
       "      <td>my favorite dinner party soup cooking the drie...</td>\n",
       "      <td>cover mushrooms with cold water and soak overn...</td>\n",
       "      <td>dried wild mushrooms beef stock butter onion c...</td>\n",
       "      <td>my favorite dinner party soup cooking the drie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147954</th>\n",
       "      <td>this is from the wsu extension office i havent...</td>\n",
       "      <td>saute in pan on medium heat in oil zucchini mu...</td>\n",
       "      <td>zucchini sliced mushrooms onions flour tortill...</td>\n",
       "      <td>this is from the wsu extension office i havent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086</th>\n",
       "      <td>recipe by tyler florencethis is soooo good the...</td>\n",
       "      <td>first thing to do is to steam the artichokes i...</td>\n",
       "      <td>fresh parsley water garlic cloves bay leaves d...</td>\n",
       "      <td>recipe by tyler florencethis is soooo good the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178888</th>\n",
       "      <td>im very picky about my chili as i get terrible...</td>\n",
       "      <td>note for a soupier chili use a oz bottle of v ...</td>\n",
       "      <td>v vegetable juice chili seasoning mix chili st...</td>\n",
       "      <td>im very picky about my chili as i get terrible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136500</th>\n",
       "      <td>this is a very quick recipe so easy my husband...</td>\n",
       "      <td>thaw frozen tilapia soak in milk for hour disc...</td>\n",
       "      <td>tilapia fillet lowfat milk panko breadcrumbs m...</td>\n",
       "      <td>this is a very quick recipe so easy my husband...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_description  \\\n",
       "97436   my favorite dinner party soup cooking the drie...   \n",
       "147954  this is from the wsu extension office i havent...   \n",
       "10086   recipe by tyler florencethis is soooo good the...   \n",
       "178888  im very picky about my chili as i get terrible...   \n",
       "136500  this is a very quick recipe so easy my husband...   \n",
       "\n",
       "                                            cleaned_steps  \\\n",
       "97436   cover mushrooms with cold water and soak overn...   \n",
       "147954  saute in pan on medium heat in oil zucchini mu...   \n",
       "10086   first thing to do is to steam the artichokes i...   \n",
       "178888  note for a soupier chili use a oz bottle of v ...   \n",
       "136500  thaw frozen tilapia soak in milk for hour disc...   \n",
       "\n",
       "                                      cleaned_ingredients  \\\n",
       "97436   dried wild mushrooms beef stock butter onion c...   \n",
       "147954  zucchini sliced mushrooms onions flour tortill...   \n",
       "10086   fresh parsley water garlic cloves bay leaves d...   \n",
       "178888  v vegetable juice chili seasoning mix chili st...   \n",
       "136500  tilapia fillet lowfat milk panko breadcrumbs m...   \n",
       "\n",
       "                                                 combined  \n",
       "97436   my favorite dinner party soup cooking the drie...  \n",
       "147954  this is from the wsu extension office i havent...  \n",
       "10086   recipe by tyler florencethis is soooo good the...  \n",
       "178888  im very picky about my chili as i get terrible...  \n",
       "136500  this is a very quick recipe so easy my husband...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeating this with the test data\n",
    "X_test['combined'] = X_test['cleaned_description'].str.cat(X_test[['cleaned_steps',\n",
    "                                                                'cleaned_ingredients']],sep=\" \")\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T21:01:53.046883Z",
     "start_time": "2021-12-03T21:01:53.025876Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e2ced4dc8873>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'combined'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m136500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1435\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1437\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# X_test['combined'].iloc[136500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling  \n",
    "\n",
    "To begin the modeling process basic, nlp appropriate,  models are created and run with both types of vectorized datasets.  This will identify which models deserve more attention and fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T03:20:16.439623Z",
     "iopub.status.busy": "2021-12-01T03:20:16.438890Z",
     "iopub.status.idle": "2021-12-01T03:20:16.465345Z",
     "shell.execute_reply": "2021-12-01T03:20:16.464459Z",
     "shell.execute_reply.started": "2021-12-01T03:20:16.439583Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import (\n",
    "    BernoulliNB,\n",
    "    ComplementNB,\n",
    "    MultinomialNB,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T03:20:16.466866Z",
     "iopub.status.busy": "2021-12-01T03:20:16.466595Z",
     "iopub.status.idle": "2021-12-01T03:20:16.470712Z",
     "shell.execute_reply": "2021-12-01T03:20:16.470119Z",
     "shell.execute_reply.started": "2021-12-01T03:20:16.466834Z"
    }
   },
   "outputs": [],
   "source": [
    "# having the CountVectorizer remove stop words\n",
    "countvect = CountVectorizer(stop_words=stop_words, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T03:20:16.472317Z",
     "iopub.status.busy": "2021-12-01T03:20:16.471737Z",
     "iopub.status.idle": "2021-12-01T03:20:44.799281Z",
     "shell.execute_reply": "2021-12-01T03:20:44.798270Z",
     "shell.execute_reply.started": "2021-12-01T03:20:16.472280Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_CV = countvect.fit_transform(X_train.combined)\n",
    "X_test_CV = countvect.transform(X_test.combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T03:20:44.800918Z",
     "iopub.status.busy": "2021-12-01T03:20:44.800569Z",
     "iopub.status.idle": "2021-12-01T03:20:44.806931Z",
     "shell.execute_reply": "2021-12-01T03:20:44.806129Z",
     "shell.execute_reply.started": "2021-12-01T03:20:44.800882Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(max_depth=3), #to keep the initial modeling quick\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(max_depth=3),\n",
    "    \"LogisticRegression\": LogisticRegression(penalty = 'elasticnet',l1_ratio =.5, solver='saga'),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, sklearn_classifier in classifiers.items():\n",
    "    classifier = sklearn_classifier\n",
    "    print(name)\n",
    "    evaluate(classifier, X_train_CV, X_test_CV, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = stop_words)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train.combined)\n",
    "X_test_tfidf = tfidf.transform(X_test.combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing KNeighborsClassifier from the list of options as it takes too long to run\n",
    "# with mediocre results when used with the CountVectorizer\n",
    "\n",
    "classifiers = {\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(max_depth=3), #to keep the initial modeling quick\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(max_depth=3),\n",
    "    \"LogisticRegression\": LogisticRegression(penalty = 'elasticnet',l1_ratio =.5, solver='saga'),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, sklearn_classifier in classifiers.items():\n",
    "    classifier = sklearn_classifier\n",
    "    print(name)\n",
    "    evaluate(classifier, X_train_tfidf, X_test_tfidf, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting result of running the basic models with both CountVectorized and TdifdVectorized data is seeing how both types produce near identical results with this data set, meaning that we could proceed with using either on the \"scores\" front.  That being said the data transformed with TdifdVectorizer did not trigger a convergence warning while being run through the LogisticRegression model, our best performing one, so we will proceed with using that dataset as the default. A possible next step would be to use both vectorizers on the dataset to see if that improves performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete This\n",
    "\n",
    "adaboost  \n",
    "Average accuracy: 0.678410389011874        +/- 0.0019428737357940935  \n",
    "Average precision: 0.6644931152129286        +/- 0.002818424532377354  \n",
    "Average recall: 0.7194833158918691        +/- 0.006592810246041841  \n",
    "Average f1 score: 0.6908708797403835        +/- 0.002527923487022844  \n",
    "Average roc_auc: 0.7486999508644392     \n",
    "\n",
    "LogisticRegression  \n",
    "Results of Cross-Validation:\n",
    "\n",
    "Average accuracy: 0.7102109937320492        +/- 0.0013818965212887846  \n",
    "Average precision: 0.699253318003423        +/- 0.0016925889402733649  \n",
    "Average recall: 0.7366901576238443        +/- 0.0026499199864471216  \n",
    "Average f1 score: 0.7174799331804131        +/- 0.0014341735471591994  \n",
    "Average roc_auc: 0.7845830512199936        +/- 0.0016728732962070642  \n",
    "  \n",
    "DecisionTreeClassifier  \n",
    "Results of Cross-Validation:  \n",
    "\n",
    "Average accuracy: 0.6305128365040875        +/- 0.0020716757364631884  \n",
    "Average precision: 0.5942676548309842        +/- 0.0018375529576019885  \n",
    "Average recall: 0.8204499451239758        +/- 0.003048503280868797  \n",
    "Average f1 score: 0.6892732858430838        +/- 0.0014567472373081848  \n",
    "Average roc_auc: 0.663055875539024        +/- 0.0024670581470042884  \n",
    "\n",
    "MultinomialNB  \n",
    "Results of Cross-Validation:  \n",
    "\n",
    "Average accuracy: 0.6767569931389056        +/- 0.0026251702785135564  \n",
    "Average precision: 0.6414577304862454        +/- 0.0025648688226974745  \n",
    "Average recall: 0.8000787507892781        +/- 0.0018291914138574743  \n",
    "Average f1 score: 0.7120383996765376        +/- 0.0019157732080198335  \n",
    "Average roc_auc: 0.749902220537832        +/- 0.003027434533991026  \n",
    "\n",
    "ComplementNB  \n",
    "Results of Cross-Validation:  \n",
    "\n",
    "Average accuracy: 0.6767569923431171        +/- 0.002685799123032517  \n",
    "Average precision: 0.6413717247113541        +/- 0.0026018594467296205  \n",
    "Average recall: 0.8004578828241925        +/- 0.0018746067605576115  \n",
    "Average f1 score: 0.7121355622030373        +/- 0.001978348558231771  \n",
    "Average roc_auc: 0.749902220537832        +/- 0.003027434533991026    \n",
    "\n",
    "BernoulliNB  \n",
    "Results of Cross-Validation:  \n",
    "\n",
    "Average accuracy: 0.6679437230396654        +/- 0.002355052279753311  \n",
    "Average precision: 0.6288082257136919        +/- 0.0020276220377248248  \n",
    "**Average recall: 0.8182334449353144        +/- 0.002507729848902346  \n",
    "Average f1 score: 0.7111205451612952        +/- 0.0019129888678486272  \n",
    "Average roc_auc: 0.7372718944460759        +/- 0.002784791836307464  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation results for each model show Logistic Regression, MultinomialNB, and ComplementNB having the best performance with the current dataset.  Interestingly the Naieve Bayes' models had near identical outputs and so moving forward we'll only work with ComplementNB as that's best suited for inbalanced datasets, which is not an issue.  Per the documentation MultinomialNB nominally requires integer feature counts even though it will word with the TdifdVectorizer's fractional outputs. Despite this we'll continue to use the Tdifd dataset as MultinomialNB performed slightly better using it. \n",
    "\n",
    "Although it didn't fare particularly well when compared with the other models the DecisionTree will also undergo some hyperparameter tuning as the initial model was in part designed to be processed quickly so simply increasing the max_depth outputs may provide better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB  \n",
    "\n",
    "The MultinomialNB model takes in only 3 parameters: alpha, fit_prior, and class_prior, making it an excellent starting point for hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pipeline including the TfidfVectorizer as well as the model\n",
    "\n",
    "mnb_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_params = {\n",
    "    'tfidf__max_df': [.5, .95, 1],\n",
    "    'tfidf__min_df': [.05, .1, 1],\n",
    "    'mnb__fit_prior': [True, False]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_clf = GridSearchCV(mnb_pipe, mnb_params)\n",
    "mnb_clf.fit(X_train.combined, y_train)\n",
    "\n",
    "mnb_results = pd.DataFrame(mnb_clf.cv_results_)\n",
    "mnb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_results.sort_values(['rank_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the top performing model the common hyperparameter was a max_df of .95 in the vectorization stage - this is a parameter that causes any word appearing more then a certain amount or percentage of times in the dataset to be dropped. This parameter was paired with a min_df, the smallest number or percentage of times a word can appear before being dropped, in the best performing values but since this is the default value of the hyperparameter it can be excluded from future GridSearches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_params2 = {\n",
    "    'tfidf__max_df': [.9, .95, .98],\n",
    "    'mnb__alpha' : [.5,1,1.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_clf2 = GridSearchCV(mnb_pipe, mnb_params)\n",
    "mnb_clf2.fit(X_train.combined, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "mnb_results2 = pd.DataFrame(mnb_clf2.cv_results_)\n",
    "mnb_results2.sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to facilitate evaluation a dataframe of scores is created to track GridSearchCV results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_tracker( gscv_results, model_name, score_df=None):\n",
    "    '''Takes in  GridSearchCV results  from 'cv_results_' attribute in dataframe form and cleans it up so it can be \n",
    "    appended to other results output, labeling each row with the other required attribute, 'model_name'. Has a score\n",
    "    tracking dataframe as an optional argument - if passed the search results will be appended to the tracker. '''\n",
    "    \n",
    "    gscv_results['model'] = model_name\n",
    "    results = gscv_results[['mean_fit_time','params','mean_test_score','std_test_score','model']]\n",
    "    \n",
    "    if score_df is not None:\n",
    "        all_scores = pd.concat([score_df, results]).copy()\n",
    "        return all_scores.sort_values('mean_test_score')\n",
    "    else:\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb2 = score_tracker(mnb_results2, 'mnb2')\n",
    "all_scores = score_tracker(mnb_results, 'mnb', mnb2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores.sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In their article about hyperparameter tuning Machine Learning Mastery notes that \"Logistic regression does not really have any critical hyperparameters to tune.\" and only calls out the 'solver', 'penalty', and 'C', parameters as having the potential to significantly affect the model's performance. Not having found additional sources to contradict the LogisticRegression GridSearch will only focus on these three. Special care needs to be taken as not all solvers work with all the penalties, however additional GridSearches will not need to be performed as the sklearn documentation for LogisticRegresssion states that the l1 penalty only works with the 'libliner' and 'saga' solvers, and the former is best suited for small datasets. While this is not true for the 'saga' solver if it proves to be the best an additional model will be run using 'l1' with 'saga'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = mnb_params = {\n",
    "    'tfidf__max_df': [.95],\n",
    "    'lr__penalty': ['none','l2'],\n",
    "    'lr__solver': ['saga','sag','newton_cg'],\n",
    "    'lr__C': [100, 1, .001],\n",
    "    'lr__max_iter': [500, 1000]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results = pd.DataFrame(lr_clf.cv_results_)\n",
    "all_scores = score_tracker(lr_results, 'lr', all_scores)\n",
    "all_scores.sort_values('mean_test_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display full contents of columns so can see all params\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since of the top models used the saga sovler I am using those parameters with the 'elasticnet' and 'l1' values\n",
    "lr2_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# no need to include the C parameter in the dictionary as the best models had C =1, the default value for the model\n",
    "lr2_params = {\n",
    "    'tfidf__max_df': [.95],\n",
    "    'lr__penalty': ['elasticnet','l1'],\n",
    "    'lr__solver': ['saga'],\n",
    "    'lr__max_iter': [500, 1000]\n",
    "}\n",
    "\n",
    "lr2_clf = GridSearchCV(lr2_pipe, lr2_params)\n",
    "lr2_clf.fit(X_train.combined, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_results = pd.DataFrame(lr2_clf.cv_results_)\n",
    "all_scores = score_tracker(lr2_results, 'lr2', all_scores)\n",
    "all_scores.sort_values('mean_test_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additional solvers and penalties failed to improve the model's performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# no need to include the C parameter in the dictionary as the best models had C =1, the default value for the model\n",
    "lr3_params = {\n",
    "    'tfidf__max_df': [.95],\n",
    "    'lr__penalty': ['elasticnet'],\n",
    "    'lr__solver': ['saga'],\n",
    "    'lr__l1_ratio': [.25,.5,.75] \n",
    "}\n",
    "\n",
    "lr3_clf = GridSearchCV(lr3_pipe, lr3_params)\n",
    "lr3_clf.fit(X_train.combined, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3_results = pd.DataFrame(lr3_clf.cv_results_)\n",
    "all_scores = score_tracker(lr3_results, 'lr3', all_scores)\n",
    "all_scores.sort_values('mean_test_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores.to_csv('data/all_scores2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
